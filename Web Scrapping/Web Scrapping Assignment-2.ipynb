{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1.Data Analysts in Banglore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required Analysis\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver address\n",
    "driver=webdriver.Chrome(r\"C:/Users/THIS PC/Downloads/chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url of the website which needs to be scrapped\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input as data analyst and loation as banglore\n",
    "\n",
    "job_search_bar=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "job_search_bar.clear()\n",
    "job_search_bar.send_keys(\"Data Analysts\")\n",
    "\n",
    "\n",
    "loc_search_bar=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "loc_search_bar.clear()\n",
    "loc_search_bar.send_keys(\"Banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search button\n",
    "search_button=driver.find_element_by_xpath('//div[@class=\"topSection\"]/section/div/form/div[3]/button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Job_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the title of the job\n",
    "try:\n",
    "    Job=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "    for j in Job[0:10]:\n",
    "        Job_Title.append(j.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "        Job_Title.append(\"Not Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the Company name        \n",
    "try:\n",
    "    name=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "    for j in name[0:10]:\n",
    "        Company_Name.append(j.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "        Company_Name.append(\"Not Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the Location of the job       \n",
    "try:\n",
    "    Jobloc=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "    for j in Jobloc[0:10]:\n",
    "        Job_Location.append(j.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "        Job_Location.append(\"Not Availble\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the experience required        \n",
    "try:\n",
    "    exp=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "    for j in exp[0:10]:\n",
    "        Experience_required.append(j.text)\n",
    "except NoSuchElementException:\n",
    "        Experience_required.append(\"Not available\")               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing list of the columns\n",
    "data=list(zip(Job_Title,Company_Name,Job_Location,Experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data frame\n",
    "df=pd.DataFrame(data,columns=[\"Job_Title\",\"Company_Name\",\"Job_Location\",\"Experience_required\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing numpy to set starting index from 1\n",
    "import numpy as np\n",
    "df.index = np.arange(1, len(df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - Consumer Analytics</td>\n",
       "      <td>Eli Lilly Services India Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - Consumer Analytics</td>\n",
       "      <td>Eli Lilly Services India Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Big Data Analysis Tool and Techniques Applicat...</td>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Servian</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sr Data Analyst - Contractual Role | Nike</td>\n",
       "      <td>ANSR GLOBAL CORPORATION PRIVATE LIMITED</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mindree Hiring-DATA Analysis</td>\n",
       "      <td>Mindtree Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Liventus, Inc.</td>\n",
       "      <td>Bengaluru(2nd Phase JP Nagar)</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst (Gameplay)</td>\n",
       "      <td>Kwalee ltd.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Kwalee ltd.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_Title  \\\n",
       "1                                        Data Analyst   \n",
       "2                   Data Analyst - Consumer Analytics   \n",
       "3                   Data Analyst - Consumer Analytics   \n",
       "4   Big Data Analysis Tool and Techniques Applicat...   \n",
       "5                                        Data Analyst   \n",
       "6           Sr Data Analyst - Contractual Role | Nike   \n",
       "7                        Mindree Hiring-DATA Analysis   \n",
       "8                                        Data Analyst   \n",
       "9                             Data Analyst (Gameplay)   \n",
       "10                                       Data Analyst   \n",
       "\n",
       "                                Company_Name                   Job_Location  \\\n",
       "1                     IBM India Pvt. Limited                      Bengaluru   \n",
       "2   Eli Lilly Services India Private Limited                      Bengaluru   \n",
       "3   Eli Lilly Services India Private Limited                      Bengaluru   \n",
       "4                Accenture Solutions Pvt Ltd                      Bengaluru   \n",
       "5                                    Servian                      Bengaluru   \n",
       "6    ANSR GLOBAL CORPORATION PRIVATE LIMITED                      Bengaluru   \n",
       "7                           Mindtree Limited                      Bengaluru   \n",
       "8                             Liventus, Inc.  Bengaluru(2nd Phase JP Nagar)   \n",
       "9                                Kwalee ltd.                      Bengaluru   \n",
       "10                               Kwalee ltd.                      Bengaluru   \n",
       "\n",
       "   Experience_required  \n",
       "1              4-6 Yrs  \n",
       "2              2-4 Yrs  \n",
       "3              2-4 Yrs  \n",
       "4              6-8 Yrs  \n",
       "5              1-6 Yrs  \n",
       "6              5-8 Yrs  \n",
       "7              5-9 Yrs  \n",
       "8              3-6 Yrs  \n",
       "9              2-7 Yrs  \n",
       "10             2-7 Yrs  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Data Scientists in Banglore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver address\n",
    "driver=webdriver.Chrome(r\"C:/Users/THIS PC/Downloads/chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url of the website which needs to be scrapped\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input as data scientist and loation as banglore\n",
    "\n",
    "job_search_bar=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "job_search_bar.clear()\n",
    "job_search_bar.send_keys(\"Data Scientist\")\n",
    "\n",
    "\n",
    "loc_search_bar=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "loc_search_bar.clear()\n",
    "loc_search_bar.send_keys(\"Banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search button\n",
    "search_button=driver.find_element_by_xpath('//div[@class=\"topSection\"]/section/div/form/div[3]/button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Job_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the title of the job\n",
    "try:\n",
    "    Job=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "    for j in Job[0:10]:\n",
    "        Job_Title.append(j.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "        Job_Title.append(\"Not Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the Company name        \n",
    "try:\n",
    "    name=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "    for j in name[0:10]:\n",
    "        Company_Name.append(j.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "        Company_Name.append(\"Not Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the Location of the job       \n",
    "try:\n",
    "    Jobloc=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "    for j in Jobloc[0:10]:\n",
    "        Job_Location.append(j.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "        Job_Location.append(\"Not Availble\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the experience required        \n",
    "try:\n",
    "    exp=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "    for j in exp[0:10]:\n",
    "        Experience_required.append(j.text)\n",
    "except NoSuchElementException:\n",
    "        Experience_required.append(\"Not available\")               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing list of the columns\n",
    "data=list(zip(Job_Title,Company_Name,Job_Location,Experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data frame\n",
    "df=pd.DataFrame(data,columns=[\"Job_Title\",\"Company_Name\",\"Job_Location\",\"Experience_required\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing numpy to set starting index from 1\n",
    "import numpy as np\n",
    "df.index = np.arange(1, len(df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst-immediate</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HCL hiring Data scientist with exp in machine ...</td>\n",
       "      <td>HCL Technologies Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist -Machine Learning</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Principal Data Scientist - Machine/Deep Learni...</td>\n",
       "      <td>Fidius advisory</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior / Lead Data Scientist</td>\n",
       "      <td>TVS CREDIT SERVICES LIMITED</td>\n",
       "      <td>Chennai, Pune, Bengaluru</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Machine Learning (Commerce BU)</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Software Developer - Data Scientist / NLP / Ma...</td>\n",
       "      <td>Cunesoft India Private Limited</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mailkit Private Limited</td>\n",
       "      <td>Chennai, Bhubaneshwar, Pune, Delhi NCR, Mumbai...</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Data Scientist - Complete Remote Work</td>\n",
       "      <td>Techolution India Private Limited</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_Title  \\\n",
       "1               Data Scientist/Data Analyst-immediate   \n",
       "2   HCL hiring Data scientist with exp in machine ...   \n",
       "3                    Data Scientist -Machine Learning   \n",
       "4   Principal Data Scientist - Machine/Deep Learni...   \n",
       "5                        Senior / Lead Data Scientist   \n",
       "6     Data Scientist - Machine Learning (Commerce BU)   \n",
       "7   Software Developer - Data Scientist / NLP / Ma...   \n",
       "8                                      Data Scientist   \n",
       "9          Lead Data Scientist - Complete Remote Work   \n",
       "10                                     Data Scientist   \n",
       "\n",
       "                                         Company_Name  \\\n",
       "1   CAIA-Center For Artificial Intelligence & Adva...   \n",
       "2                            HCL Technologies Limited   \n",
       "3                   BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "4                                     Fidius advisory   \n",
       "5                         TVS CREDIT SERVICES LIMITED   \n",
       "6                   BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "7                      Cunesoft India Private Limited   \n",
       "8                             Mailkit Private Limited   \n",
       "9                   Techolution India Private Limited   \n",
       "10                             IBM India Pvt. Limited   \n",
       "\n",
       "                                         Job_Location Experience_required  \n",
       "1                 Chennai, Pune, Bengaluru, Hyderabad             0-3 Yrs  \n",
       "2                                           Bengaluru            5-10 Yrs  \n",
       "3                                           Bengaluru             4-8 Yrs  \n",
       "4                                           Bengaluru            8-13 Yrs  \n",
       "5                            Chennai, Pune, Bengaluru             3-8 Yrs  \n",
       "6                                           Bengaluru             4-6 Yrs  \n",
       "7                               Bengaluru / Bangalore             3-6 Yrs  \n",
       "8   Chennai, Bhubaneshwar, Pune, Delhi NCR, Mumbai...             4-9 Yrs  \n",
       "9   Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...            9-14 Yrs  \n",
       "10                                          Bengaluru             6-8 Yrs  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3.Data Scientist in Delhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver address\n",
    "driver=webdriver.Chrome(r\"C:/Users/THIS PC/Downloads/chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url of the website which needs to be scrapped\n",
    "url=\"https://www.naukri.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input as data scientist and loation as banglore\n",
    "\n",
    "job_search_bar=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "job_search_bar.clear()\n",
    "job_search_bar.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search button\n",
    "search_button=driver.find_element_by_xpath('//div[@class=\"topSection\"]/section/div/form/div[3]/button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location Filter \n",
    "loc_filter=driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft\"]')\n",
    "for i in loc_filter:\n",
    "    if i.text=='Delhi/NCR':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explicit delay\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salary filter\n",
    "sal_filter=driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft\"]')\n",
    "for i in sal_filter:\n",
    "    if i.text==\"3-6 Lakhs\":\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Job_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the title of the job\n",
    "try:\n",
    "    Job=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "    for j in Job[0:10]:\n",
    "        Job_Title.append(j.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "        Job_Title.append(\"Not Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the Location of the job       \n",
    "try:\n",
    "    Jobloc=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "    for j in Jobloc[0:10]:\n",
    "        Job_Location.append(j.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "        Job_Location.append(\"Not Availble\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the Company name        \n",
    "try:\n",
    "    name=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "    for j in name[0:10]:\n",
    "        Company_Name.append(j.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "        Company_Name.append(\"Not Available\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the experience required        \n",
    "try:\n",
    "    exp=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "    for j in exp[0:10]:\n",
    "        Experience_required.append(j.text)\n",
    "except NoSuchElementException:\n",
    "        Experience_required.append(\"Not available\")               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing list of the columns\n",
    "data=list(zip(Job_Title,Company_Name,Job_Location,Experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data frame\n",
    "df=pd.DataFrame(data,columns=[\"Job_Title\",\"Company_Name\",\"Job_Location\",\"Experience_required\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing numpy to set starting index from 1\n",
    "import numpy as np\n",
    "df.index = np.arange(1, len(df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amity University</td>\n",
       "      <td>Faridabad, Delhi NCR, Ghaziabad</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist - Computer Vision</td>\n",
       "      <td>IRIS SOFTWARE Inc</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine Learning/ NLP</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>PEOPLE STAFFING SOLUTIONS</td>\n",
       "      <td>Pune, Bengaluru, Hyderabad, Gurgaon</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Tableau/Power BI</td>\n",
       "      <td>Talent Stock Solutions</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Python/Machine Learning</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>Noida</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - IT</td>\n",
       "      <td>Ehireo</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_Title  \\\n",
       "1                                      Data Scientist   \n",
       "2                                      Data Scientist   \n",
       "3             Senior Data Scientist - Computer Vision   \n",
       "4              Data Scientist - Machine Learning/ NLP   \n",
       "5                                      Data Scientist   \n",
       "6                   Data Scientist - Tableau/Power BI   \n",
       "7   GCP Skilled Analytics Resources (Data engineer...   \n",
       "8            Data Scientist - Python/Machine Learning   \n",
       "9                                 Data Scientist - IT   \n",
       "10                                     Data Scientist   \n",
       "\n",
       "                          Company_Name  \\\n",
       "1                       Country Veggie   \n",
       "2                     Amity University   \n",
       "3                    IRIS SOFTWARE Inc   \n",
       "4                               TalPro   \n",
       "5            PEOPLE STAFFING SOLUTIONS   \n",
       "6               Talent Stock Solutions   \n",
       "7   Aerial Telecom Solutions Pvt. Ltd.   \n",
       "8                                Jubna   \n",
       "9                               Ehireo   \n",
       "10              IBM India Pvt. Limited   \n",
       "\n",
       "                                         Job_Location Experience_required  \n",
       "1   Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...             1-3 Yrs  \n",
       "2                     Faridabad, Delhi NCR, Ghaziabad             6-8 Yrs  \n",
       "3                                           Delhi NCR             4-9 Yrs  \n",
       "4                                    Gurgaon Gurugram             2-6 Yrs  \n",
       "5                 Pune, Bengaluru, Hyderabad, Gurgaon             3-6 Yrs  \n",
       "6                                               Delhi             1-3 Yrs  \n",
       "7                            Pune, Bengaluru, Gurgaon             3-8 Yrs  \n",
       "8                                               Noida             5-8 Yrs  \n",
       "9                                             Gurgaon             4-9 Yrs  \n",
       "10                                   Gurgaon Gurugram             3-5 Yrs  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 Data Scientists in Noida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver address\n",
    "driver=webdriver.Chrome(r\"C:/Users/THIS PC/Downloads/chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver address\n",
    "url=\"https://www.glassdoor.co.in/Job/index.htm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input as data scientist and loation as noida\n",
    "\n",
    "job_search_bar=driver.find_element_by_id(\"KeywordSearch\")\n",
    "job_search_bar.clear()\n",
    "job_search_bar.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_search_bar=driver.find_element_by_id(\"LocationSearch\")\n",
    "loc_search_bar.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_search_bar.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search button\n",
    "search_button=driver.find_element_by_id('HeroSearchButton')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "\n",
    "Company_Name=[]\n",
    "Posted_Day=[]\n",
    "Rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the Company name        \n",
    "try:\n",
    "    name=driver.find_elements_by_xpath('//div[@class=\"d-flex justify-content-between align-items-start\"]/a/span')\n",
    "    for j in name[0:10]:\n",
    "        Company_Name.append(j.text)\n",
    "        \n",
    "except NoSuchElementException:\n",
    "        Company_Name.append(\"Not Available\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the posted day required        \n",
    "try:\n",
    "    day=driver.find_elements_by_xpath('//div[@class=\"d-flex align-items-end pl-std css-mi55ob\"]')\n",
    "    for j in day[0:10]:\n",
    "        Posted_Day.append(j.text)\n",
    "except NoSuchElementException:\n",
    "        Posted_Day.append(\"Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting rating\n",
    "try:\n",
    "    rat=driver.find_elements_by_xpath('//div[@class=\"d-flex flex-column css-x75kgh e1rrn5ka3\"]/span')\n",
    "    for j in rat[0:10]:\n",
    "        Rating.append(j.text)\n",
    "except NoSuchElementException:\n",
    "        Rating.append(\"Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing list of the columns\n",
    "data=list(zip(Company_Name,Posted_Day,Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data frame\n",
    "df=pd.DataFrame(data,columns=[\"Company_Name\",\"Posted_Day\",\"Rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing numpy to set starting index from 1\n",
    "import numpy as np\n",
    "df.index = np.arange(1, len(df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Posted_Day</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>2d</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BlackRock</td>\n",
       "      <td>6d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abc consultants</td>\n",
       "      <td>19d</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brickred</td>\n",
       "      <td>9d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WishFin</td>\n",
       "      <td>1d</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>27d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Terra Economics &amp; Analytics Lab (TEAL)</td>\n",
       "      <td>20d</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xtLytics</td>\n",
       "      <td>5d</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gauge Data Solutions</td>\n",
       "      <td>18d</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Priority Vendor</td>\n",
       "      <td>18d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Company_Name Posted_Day Rating\n",
       "1                       Ericsson-Worldwide         2d    4.0\n",
       "2                                BlackRock         6d    4.1\n",
       "3                          abc consultants        19d    4.2\n",
       "4                                 Brickred         9d    3.7\n",
       "5                                  WishFin         1d    4.0\n",
       "6                           Biz2Credit Inc        27d    3.7\n",
       "7   Terra Economics & Analytics Lab (TEAL)        20d    4.9\n",
       "8                                 xtLytics         5d    3.0\n",
       "9                     Gauge Data Solutions        18d    3.1\n",
       "10                         Priority Vendor        18d    3.7"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5.Salary data for Data Scientist designation in Noida location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver address\n",
    "driver=webdriver.Chrome(r\"C:/Users/THIS PC/Downloads/chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver address\n",
    "url=\"https://www.glassdoor.co.in/Salaries/index.htm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input as data scientist and loation as noida\n",
    "\n",
    "job_search_bar=driver.find_element_by_id(\"KeywordSearch\")\n",
    "job_search_bar.clear()\n",
    "job_search_bar.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_search_bar=driver.find_element_by_id(\"LocationSearch\")\n",
    "loc_search_bar.clear()\n",
    "loc_search_bar.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search button\n",
    "search_button=driver.find_element_by_id('HeroSearchButton')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "\n",
    "Company_Name=[]\n",
    "Number_of_salaries=[]\n",
    "Average_salary=[]\n",
    "Min_salary=[]\n",
    "Max_salary=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the Company name\n",
    "try:\n",
    "    com=driver.find_elements_by_xpath('//p[@class=\"m-0 \"]')\n",
    "    for j in com[0:10]:\n",
    "        Company_Name.append(j.text)\n",
    "except NoSuchElementException:\n",
    "        Company_Name.append(\"Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the number of salaries required        \n",
    "try:\n",
    "    nos=driver.find_elements_by_xpath('//p[@class=\"css-1uyte9r css-1kuy7z7 m-0 \"]')\n",
    "    for j in nos[0:10]:\n",
    "        Number_of_salaries.append(j.text)\n",
    "except NoSuchElementException:\n",
    "        Number_of_salaries.append(\"Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting average salary\n",
    "try:\n",
    "    avg=driver.find_elements_by_xpath('//div[@class=\"col-2 d-none d-md-flex flex-row justify-content-end\"]')\n",
    "    for j in avg[0:10]:\n",
    "        Average_salary.append(j.text)\n",
    "except NoSuchElementException:\n",
    "        Average_salary.append(\"Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting minimum salary\n",
    "try:\n",
    "    mini=driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container \"]/span[1]')\n",
    "    for j in mini[0:10]:\n",
    "        Min_salary.append(j.text)\n",
    "except NoSuchElementException:\n",
    "        Min_salary.append(\"Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting maximum salary\n",
    "try:\n",
    "    maxi=driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container \"]/span[2]')\n",
    "    for j in maxi[0:10]:\n",
    "        Max_salary.append(j.text)\n",
    "except NoSuchElementException:\n",
    "        Max_salary.append(\"Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing list of the columns\n",
    "data=list(zip(Company_Name,Number_of_salaries,Average_salary,Min_salary,Max_salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data frame\n",
    "df=pd.DataFrame(data,columns=[\"Company_name\",\"Number_of_salaries\",\"Average_salary\",\"Min_salary\",\"Max_salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing numpy to set starting index from 1\n",
    "import numpy as np\n",
    "df.index = np.arange(1, len(df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Number_of_salaries</th>\n",
       "      <th>Average_salary</th>\n",
       "      <th>Min_salary</th>\n",
       "      <th>Max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>13 salaries</td>\n",
       "      <td>₹ 12,81,419\\n/yr</td>\n",
       "      <td>₹456K</td>\n",
       "      <td>₹11,789K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>₹ 7,52,052\\n/yr</td>\n",
       "      <td>₹420K</td>\n",
       "      <td>₹1,636K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 9,98,925\\n/yr</td>\n",
       "      <td>₹585K</td>\n",
       "      <td>₹2,200K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 6,02,000\\n/yr</td>\n",
       "      <td>₹336K</td>\n",
       "      <td>₹1,024K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IBM</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 7,71,657\\n/yr</td>\n",
       "      <td>₹595K</td>\n",
       "      <td>₹2,769K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 13,55,346\\n/yr</td>\n",
       "      <td>₹727K</td>\n",
       "      <td>₹1,597K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 7,91,015\\n/yr</td>\n",
       "      <td>₹509K</td>\n",
       "      <td>₹1,168K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹ 12,15,138\\n/yr</td>\n",
       "      <td>₹629K</td>\n",
       "      <td>₹1,719K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹ 10,21,889\\n/yr</td>\n",
       "      <td>₹804K</td>\n",
       "      <td>₹1,281K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5 salaries</td>\n",
       "      <td>₹ 10,00,000\\n/yr</td>\n",
       "      <td>₹205K</td>\n",
       "      <td>₹1,835K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Company_name Number_of_salaries    Average_salary  \\\n",
       "1                        Delhivery        13 salaries  ₹ 12,81,419\\n/yr   \n",
       "2               Ericsson-Worldwide        11 salaries   ₹ 7,52,052\\n/yr   \n",
       "3                        Accenture        10 salaries   ₹ 9,98,925\\n/yr   \n",
       "4        Tata Consultancy Services         9 salaries   ₹ 6,02,000\\n/yr   \n",
       "5                              IBM         9 salaries   ₹ 7,71,657\\n/yr   \n",
       "6               UnitedHealth Group         9 salaries  ₹ 13,55,346\\n/yr   \n",
       "7               Valiance Solutions         8 salaries   ₹ 7,91,015\\n/yr   \n",
       "8                       Innovaccer         7 salaries  ₹ 12,15,138\\n/yr   \n",
       "9   Cognizant Technology Solutions         6 salaries  ₹ 10,21,889\\n/yr   \n",
       "10                   ZS Associates         5 salaries  ₹ 10,00,000\\n/yr   \n",
       "\n",
       "   Min_salary Max_salary  \n",
       "1       ₹456K   ₹11,789K  \n",
       "2       ₹420K    ₹1,636K  \n",
       "3       ₹585K    ₹2,200K  \n",
       "4       ₹336K    ₹1,024K  \n",
       "5       ₹595K    ₹2,769K  \n",
       "6       ₹727K    ₹1,597K  \n",
       "7       ₹509K    ₹1,168K  \n",
       "8       ₹629K    ₹1,719K  \n",
       "9       ₹804K    ₹1,281K  \n",
       "10      ₹205K    ₹1,835K  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6.100 Sunglasses-flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver address\n",
    "driver=webdriver.Chrome(r\"C:/Users/THIS PC/Downloads/chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url of the website which needs to be scrapped\n",
    "url=\"https://www.flipkart.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input as sunglasses\n",
    "\n",
    "prod_search_bar=driver.find_element_by_xpath('//div[@class=\"_3OO5Xc\"]/input')\n",
    "prod_search_bar.clear()\n",
    "prod_search_bar.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the pop up window\n",
    "close_button=driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "close_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search button\n",
    "search_button=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Brand=[]\n",
    "Product_description=[]\n",
    "Price=[]\n",
    "Discount=[]\n",
    "URL=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    \n",
    "    #Extracting the brand\n",
    "    brand=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand[0:101]:\n",
    "        Brand.append(i.text)\n",
    "        \n",
    "     #Extracting product description\n",
    "    prod=driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]/a[1]')\n",
    "    for i in prod[0:101]:\n",
    "        Product_description.append(i.text)   \n",
    "    \n",
    "    #Extracting price\n",
    "    price=driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]/a[2]/div/div[1]')\n",
    "    for i in price[0:101]:\n",
    "        Price.append(i.text)\n",
    "        \n",
    "        \n",
    "    #Extracting discount\n",
    "    dis=driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]/a[2]/div/div[3]')\n",
    "    for i in dis[0:101]:    \n",
    "        Discount.append(i.text)\n",
    "        \n",
    "    driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "    time.sleep(3)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing list of the columns\n",
    "data=list(zip(Brand,Product_description,Price,Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data frame\n",
    "df=pd.DataFrame(data,columns=[\"Brand\",\"Product_description\",\"Price\",\"Discount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing numpy to set starting index from 1\n",
    "import numpy as np\n",
    "df.index = np.arange(1, len(df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David Martin</td>\n",
       "      <td>Gradient, UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹210</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Martin</td>\n",
       "      <td>Gradient, UV Protection Aviator Sunglasses (Fr...</td>\n",
       "      <td>₹335</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shah collections</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹239</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>like future</td>\n",
       "      <td>Mirrored Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹181</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>I Flash</td>\n",
       "      <td>Gradient, UV Protection Round Sunglasses (Free...</td>\n",
       "      <td>₹123</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>funglasses</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Ro...</td>\n",
       "      <td>₹125</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Winsome</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹180</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Gansta</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹284</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                Product_description  \\\n",
       "1        David Martin    Gradient, UV Protection Aviator Sunglasses (58)   \n",
       "2        David Martin  Gradient, UV Protection Aviator Sunglasses (Fr...   \n",
       "3          Phenomenal  UV Protection, Mirrored Retro Square Sunglasse...   \n",
       "4    shah collections  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "5         like future            Mirrored Aviator Sunglasses (Free Size)   \n",
       "..                ...                                                ...   \n",
       "116           I Flash  Gradient, UV Protection Round Sunglasses (Free...   \n",
       "117        Phenomenal  UV Protection, Mirrored Retro Square Sunglasse...   \n",
       "118        funglasses  UV Protection, Night Vision, Riding Glasses Ro...   \n",
       "119           Winsome                UV Protection Round Sunglasses (54)   \n",
       "120            Gansta              UV Protection Aviator Sunglasses (57)   \n",
       "\n",
       "    Price Discount  \n",
       "1    ₹210  80% off  \n",
       "2    ₹335  76% off  \n",
       "3    ₹379  81% off  \n",
       "4    ₹239  76% off  \n",
       "5    ₹181  83% off  \n",
       "..    ...      ...  \n",
       "116  ₹123  87% off  \n",
       "117  ₹399  80% off  \n",
       "118  ₹125  83% off  \n",
       "119  ₹180  81% off  \n",
       "120  ₹284  85% off  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7.IPHONE 11 Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver address\n",
    "driver=webdriver.Chrome(r\"C:/Users/THIS PC/Downloads/chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url of the website which needs to be scrapped\n",
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace=FLIPKART\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Rating=[]\n",
    "Review_summary=[]\n",
    "Full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    #Extracting the rating\n",
    "    rating=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for j in rating:\n",
    "        Rating.append(j.text)\n",
    "        \n",
    "    #Extracting the review summary    \n",
    "    review=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "    for j in review:\n",
    "        Review_summary.append(j.text)\n",
    "    \n",
    "    #Extracting the Full review\n",
    "    flrvw=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "    for j in flrvw:\n",
    "        Full_review.append(j.text)\n",
    "        \n",
    "     #Code for moving into next page   \n",
    "    driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "    time.sleep(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of columns\n",
    "data=list(zip(Rating,Review_summary,Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe\n",
    "df=pd.DataFrame(data,columns=[\"Rating\",\"Review_summary\",\"Full_review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing numpy to set starting index from 1\n",
    "import numpy as np\n",
    "df.index = np.arange(1, len(df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is my first ever I phone. Before this I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Well you all know the specifications . One of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Best Quality Product OF iPhone Series , Sound ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>The built quality is not very premium.\\nThe ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rating         Review_summary  \\\n",
       "1        5       Perfect product!   \n",
       "2        5          Great product   \n",
       "3        5     Highly recommended   \n",
       "4        5       Perfect product!   \n",
       "5        5       Perfect product!   \n",
       "..     ...                    ...   \n",
       "96       5              Wonderful   \n",
       "97       5          Great product   \n",
       "98       5     Highly recommended   \n",
       "99       5  Mind-blowing purchase   \n",
       "100      5      Terrific purchase   \n",
       "\n",
       "                                           Full_review  \n",
       "1    Amazing phone with great cameras and better ba...  \n",
       "2    Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "3    iphone 11 is a very good phone to buy only if ...  \n",
       "4    It’s a must buy who is looking for an upgrade ...  \n",
       "5    Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "..                                                 ...  \n",
       "96   This is my first ever I phone. Before this I w...  \n",
       "97   Well you all know the specifications . One of ...  \n",
       "98   It's my first time to use iOS phone and I am l...  \n",
       "99   Best Quality Product OF iPhone Series , Sound ...  \n",
       "100  The built quality is not very premium.\\nThe ba...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8.Sneakers-Flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver address\n",
    "driver=webdriver.Chrome(r\"C:/Users/THIS PC/Downloads/chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url of the website which needs to be scrapped\n",
    "url=\"https://www.flipkart.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving input as sneakers\n",
    "\n",
    "prod_search_bar=driver.find_element_by_xpath('//div[@class=\"_3OO5Xc\"]/input')\n",
    "prod_search_bar.clear()\n",
    "prod_search_bar.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#closing the pop up window\n",
    "close_button=driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "close_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search button\n",
    "search_button=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Brand=[]\n",
    "Product_description=[]\n",
    "Price=[]\n",
    "Discount=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    \n",
    "    #Extracting the brand\n",
    "    brand=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand[0:101]:\n",
    "        Brand.append(i.text)\n",
    "        \n",
    "     #Extracting product description\n",
    "    prod=driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]/a[1]')\n",
    "    for i in prod[0:101]:\n",
    "        Product_description.append(i.text)   \n",
    "    \n",
    "    #Extracting price\n",
    "    price=driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]/a[2]/div/div[1]')\n",
    "    for i in price[0:101]:\n",
    "        Price.append(i.text)\n",
    "        \n",
    "        \n",
    "    #Extracting discount\n",
    "    dis=driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]/a[2]/div/div[3]')\n",
    "    for i in dis[0:101]:    \n",
    "        Discount.append(i.text)\n",
    "        \n",
    "    driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "    time.sleep(3)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing list of the columns\n",
    "data=list(zip(Brand,Product_description,Price,Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data frame\n",
    "df=pd.DataFrame(data,columns=[\"Brand\",\"Product_description\",\"Price\",\"Discount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing numpy to set starting index from 1\n",
    "import numpy as np\n",
    "df.index = np.arange(1, len(df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India hub</td>\n",
       "      <td>Canvas casual sneaker shoes Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Chevit Latest Fashion Combo Pack of 2 Pairs Ca...</td>\n",
       "      <td>₹570</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹378</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Combo Pack of 4 Latest Collection Stylish Casu...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Red Rose</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹359</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Stefano Rads</td>\n",
       "      <td>Classy Sneakers For Men</td>\n",
       "      <td>₹260</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Rockfield</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹359</td>\n",
       "      <td>59% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Smart Casuals Canvas Shoes Combo pack of 2 Sne...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>believe</td>\n",
       "      <td>casual for men (white 07) Sneakers For Men</td>\n",
       "      <td>₹402</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand                                Product_description  \\\n",
       "1              India hub       Canvas casual sneaker shoes Sneakers For Men   \n",
       "2                 Chevit  Chevit Latest Fashion Combo Pack of 2 Pairs Ca...   \n",
       "3                 Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
       "4           Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "5    World Wear Footwear  Combo Pack of 4 Latest Collection Stylish Casu...   \n",
       "..                   ...                                                ...   \n",
       "96              Red Rose                                   Sneakers For Men   \n",
       "97          Stefano Rads                            Classy Sneakers For Men   \n",
       "98             Rockfield                                   Sneakers For Men   \n",
       "99                Chevit  Smart Casuals Canvas Shoes Combo pack of 2 Sne...   \n",
       "100              believe         casual for men (white 07) Sneakers For Men   \n",
       "\n",
       "    Price Discount  \n",
       "1    ₹499  83% off  \n",
       "2    ₹570  61% off  \n",
       "3    ₹499  75% off  \n",
       "4    ₹378  62% off  \n",
       "5    ₹499  75% off  \n",
       "..    ...      ...  \n",
       "96   ₹359  64% off  \n",
       "97   ₹260  70% off  \n",
       "98   ₹359  59% off  \n",
       "99   ₹299  62% off  \n",
       "100  ₹402  52% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9.Black Shoes-Myntra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webdriver address\n",
    "driver=webdriver.Chrome(r\"C:/Users/THIS PC/Downloads/chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url of the website which needs to be scrapped\n",
    "url=\"https://www.myntra.com/shoes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Filter \n",
    "price_filter=driver.find_elements_by_xpath('//label[@class=\"common-customCheckbox vertical-filters-label\"]')\n",
    "for i in price_filter:\n",
    "    if i.text=='Rs. 6649 to Rs. 13099(2257)':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color filter\n",
    "col_filter=driver.find_elements_by_xpath('//li[@class=\"colour-listItem\"]')\n",
    "for i in col_filter:\n",
    "    if i.text==\"Black (20095)\":\n",
    "        i.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Brand=[]\n",
    "Short_description=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,3):\n",
    "    #Extracting the brand\n",
    "    brand=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "    for j in brand:\n",
    "        Brand.append(j.text)\n",
    "        \n",
    "    #Extracting the short_description    \n",
    "    desc=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "    for j in desc:\n",
    "        Short_description.append(j.text)\n",
    "    \n",
    "    #Extracting the price\n",
    "    try:\n",
    "        price=driver.find_elements_by_xpath('//div[@class=\"product-price\"]/span/span[1]')\n",
    "        for j in price:\n",
    "            Price.append(j.text)\n",
    "            \n",
    "    except NoSuvhElementException:\n",
    "        Price.append(\"Not Available\")\n",
    "        \n",
    "     #Code for moving into next page   \n",
    "    driver.find_element_by_xpath('//li[@class=\"pagination-next\"]').click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of columns\n",
    "data=list(zip(Brand,Short_description,Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe\n",
    "df=pd.DataFrame(data,columns=[\"Brand\",\"Short_desription\",\"Price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing numpy to set starting index from 1\n",
    "import numpy as np\n",
    "df.index = np.arange(1, len(df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short_desription</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AfroJack</td>\n",
       "      <td>Men Slip-On Sneakers</td>\n",
       "      <td>Rs. 699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MENGLER</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AfroJack</td>\n",
       "      <td>Men Slip-On Sneakers</td>\n",
       "      <td>Rs. 699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Woakers</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mactree</td>\n",
       "      <td>Men Solid Sneakers</td>\n",
       "      <td>Rs. 682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>SALARIO</td>\n",
       "      <td>Women Woven Design Heels</td>\n",
       "      <td>Rs. 7916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>ZAPATOZ</td>\n",
       "      <td>Women Heeled Boots</td>\n",
       "      <td>Rs. 997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Catwalk</td>\n",
       "      <td>Women One Toe Flats</td>\n",
       "      <td>Rs. 1889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "      <td>Rs. 2549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Women Solid Sneakers</td>\n",
       "      <td>Rs. 6153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand           Short_desription     Price\n",
       "1   AfroJack       Men Slip-On Sneakers   Rs. 699\n",
       "2    MENGLER          Men Walking Shoes   Rs. 689\n",
       "3   AfroJack       Men Slip-On Sneakers   Rs. 699\n",
       "4    Woakers          Men Running Shoes   Rs. 659\n",
       "5    Mactree         Men Solid Sneakers   Rs. 682\n",
       "..       ...                        ...       ...\n",
       "86   SALARIO   Women Woven Design Heels  Rs. 7916\n",
       "87   ZAPATOZ         Women Heeled Boots   Rs. 997\n",
       "88   Catwalk        Women One Toe Flats  Rs. 1889\n",
       "89  Red Tape  Men Leather Driving Shoes  Rs. 2549\n",
       "90  Roadster       Women Solid Sneakers  Rs. 6153\n",
       "\n",
       "[90 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10.Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Webdriver address\n",
    "driver=webdriver.Chrome(r\"C:/Users/THIS PC/Downloads/chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.amazon.in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giving input as laptops\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search_bar.clear()                                              \n",
    "search_bar.send_keys(\"laptops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seach for laptops\n",
    "search_button = driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]')       \n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i7 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i9 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping Titles\n",
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in titles[:10]:\n",
    "    Title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping Price\n",
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in prices[:10]:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating Ratings\n",
    "UR=[]\n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "for i in urls[0:10]:\n",
    "    UR.append(i.get_attribute('href'))\n",
    "for url in UR:\n",
    "    driver.get(url)\n",
    "    try:                  \n",
    "        rate=driver.find_element_by_xpath(\"//span[@id='acrCustomerReviewText']\")\n",
    "        rate.click()                                                      \n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "        Ratings.append(rating.text)\n",
    "        \n",
    "    except NoSuchElementException :\n",
    "        Ratings.append(\"NO rating\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(zip(Title,price,Ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data,columns=[\"Title\",\"price\",\"Ratings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Renewed) Dell INS 5482 (CORE i7-8550U/8GB/256...</td>\n",
       "      <td>57,990</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Renewed) Dell Latitude 7389 13.3 inch 2-in-1 ...</td>\n",
       "      <td>59,990</td>\n",
       "      <td>2.9 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Renewed) Dell Latitude E5570 15-inch FHD-Touc...</td>\n",
       "      <td>64,499</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) Dell Latitude E6420 14 Inch Laptop (...</td>\n",
       "      <td>35,000</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Renewed) Dell Latitude E6420 14 Inch Laptop (...</td>\n",
       "      <td>35,000</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) Dell Latitude E6420 14 Inch Laptop (...</td>\n",
       "      <td>37,000</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) Dell Latitude E7470 14-inch Laptop (...</td>\n",
       "      <td>55,299</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) DELL Gaming-G3 3590 15.6-inch Laptop...</td>\n",
       "      <td>89,990</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3i 10th Gen Intel Core i...</td>\n",
       "      <td>74,990</td>\n",
       "      <td>3.8 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>59,999</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   price       Ratings\n",
       "0  (Renewed) Dell INS 5482 (CORE i7-8550U/8GB/256...  57,990     NO rating\n",
       "1  (Renewed) Dell Latitude 7389 13.3 inch 2-in-1 ...  59,990  2.9 out of 5\n",
       "2  (Renewed) Dell Latitude E5570 15-inch FHD-Touc...  64,499     NO rating\n",
       "3  (Renewed) Dell Latitude E6420 14 Inch Laptop (...  35,000     NO rating\n",
       "4  (Renewed) Dell Latitude E6420 14 Inch Laptop (...  35,000     NO rating\n",
       "5  (Renewed) Dell Latitude E6420 14 Inch Laptop (...  37,000     NO rating\n",
       "6  (Renewed) Dell Latitude E7470 14-inch Laptop (...  55,299     NO rating\n",
       "7  (Renewed) DELL Gaming-G3 3590 15.6-inch Laptop...  89,990     NO rating\n",
       "8  Lenovo IdeaPad Gaming 3i 10th Gen Intel Core i...  74,990  3.8 out of 5\n",
       "9  Mi Notebook Horizon Edition 14 Intel Core i7-1...  59,999  4.2 out of 5"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF DOCUMENT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
