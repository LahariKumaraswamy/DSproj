{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Data Collection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4-qf5NSohLp",
        "outputId": "594d2ec3-6d79-4434-a3ff-724dbe464bba"
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update \n",
        "!apt install chromium-chromedriver\n",
        "\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "driver =webdriver.Chrome('chromedriver',chrome_options=chrome_options)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [61.8 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,415 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,185 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [450 kB]\n",
            "Get:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Ign:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [800 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,771 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [481 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [33.5 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,185 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,619 kB]\n",
            "Get:26 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [906 kB]\n",
            "Get:27 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.9 kB]\n",
            "Get:28 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [41.6 kB]\n",
            "Fetched 13.3 MB in 4s (3,643 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 48 not upgraded.\n",
            "Need to get 86.0 MB of archives.\n",
            "After this operation, 298 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 91.0.4472.77-0ubuntu0.18.04.1 [1,124 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 91.0.4472.77-0ubuntu0.18.04.1 [76.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 91.0.4472.77-0ubuntu0.18.04.1 [3,948 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 91.0.4472.77-0ubuntu0.18.04.1 [4,838 kB]\n",
            "Fetched 86.0 MB in 4s (23.5 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_91.0.4472.77-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (91.0.4472.77-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_91.0.4472.77-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (91.0.4472.77-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_91.0.4472.77-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (91.0.4472.77-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_91.0.4472.77-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (91.0.4472.77-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (91.0.4472.77-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (91.0.4472.77-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (91.0.4472.77-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (91.0.4472.77-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: use options instead of chrome_options\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: use options instead of chrome_options\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHg4twq3pAuv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from selenium import webdriver\n",
        "import shutil\n",
        "import requests\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import os\n",
        "import time\n",
        "from selenium.common.exceptions import NoSuchElementException"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH-nt-qmpAwf"
      },
      "source": [
        "# Creating empty list to store labels \n",
        "labels = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwGdvaicpA0Z"
      },
      "source": [
        "# function to create a directory\n",
        "\n",
        "def directory(folder):\n",
        "    img_dir = os.path.join(os.getcwd(), folder)\n",
        "    if not os.path.exists(img_dir):\n",
        "        os.makedirs(img_dir)\n",
        "        \n",
        "    return folder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3rIujeMpA2a"
      },
      "source": [
        "# Calling the above function\n",
        "\n",
        "folder = directory(\"/content/drive/MyDrive/Projects/Image Processing/data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKr4dp1OpA50"
      },
      "source": [
        "# Function for scraping, downloading and storing the required images/data.\n",
        "\n",
        "def images(url, folder, labels, label):\n",
        "    \n",
        "    # Opening drive \n",
        "    amazon_url = driver.get(url)\n",
        "    \n",
        "    time.sleep(3)\n",
        "\n",
        "    # Locating the search bar\n",
        "    search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
        "    search_bar.clear()\n",
        "    category = input('Search Category : ')\n",
        "    search_bar.send_keys(category)\n",
        "\n",
        "    #locating the button and clicking it to search the category\n",
        "    button = driver.find_element_by_id('nav-search-submit-button')\n",
        "    button.click()\n",
        "\n",
        "    time.sleep(3)\n",
        "    \n",
        "    # Creating empty list fto sotre data\n",
        "    image_urls = []\n",
        "    \n",
        "    # Loop for iterating the pages and thus scraping the images\n",
        "    for page in range(1, 6):\n",
        "        print('\\nPage', page)\n",
        "        \n",
        "        time.sleep(3)\n",
        "\n",
        "        # Giving path of the images to be scrapped\n",
        "        images = driver.find_elements_by_xpath(\"//img[@class = 's-image']\")\n",
        "\n",
        "        # Getting the source/link of the images.\n",
        "        for img in images:\n",
        "            source = img.get_attribute('src')\n",
        "            image_urls.append(source)\n",
        "    \n",
        "        # Downloading the images and saving the same in the respective directory.\n",
        "        for i, image_link in enumerate(image_urls):\n",
        "            response = requests.get(image_link)\n",
        "\n",
        "            # Downloading the images\n",
        "            image_name = folder + '/' + category + '_' + str(i+1) + '.jpg'\n",
        "            with open(image_name, 'wb') as file:\n",
        "                file.write(response.content)\n",
        "\n",
        "        time.sleep(3)\n",
        "        \n",
        "        print(\"Downloads of images from Page\", page, \"is completed! \\n\")\n",
        "        \n",
        "        time.sleep(3)\n",
        "\n",
        "        # Moving to the next page.\n",
        "        next_page = driver.find_element_by_xpath(\"//li[@class = 'a-last']/a\")\n",
        "        next_page.click()\n",
        "        \n",
        "    print(\"Total images downlaoded of\", str(category), \": \", len(image_urls))\n",
        "    for i in image_urls:\n",
        "        labels.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqvu5sKYpA75"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILtTsNHXpzBf"
      },
      "source": [
        "# Saree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5fC74JBpA_S",
        "outputId": "70a2dda3-0805-48b4-9baa-876464f97347"
      },
      "source": [
        "# Calling the function and scraping the 'Sarees (women)' category images.\n",
        "\n",
        "images(\"https://www.amazon.com/\", folder, labels, 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search Category : saree\n",
            "\n",
            "Page 1\n",
            "Downloads of images from Page 1 is completed! \n",
            "\n",
            "\n",
            "Page 2\n",
            "Downloads of images from Page 2 is completed! \n",
            "\n",
            "\n",
            "Page 3\n",
            "Downloads of images from Page 3 is completed! \n",
            "\n",
            "\n",
            "Page 4\n",
            "Downloads of images from Page 4 is completed! \n",
            "\n",
            "\n",
            "Page 5\n",
            "Downloads of images from Page 5 is completed! \n",
            "\n",
            "Total images downlaoded of saree :  286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W46ast8FqnpD"
      },
      "source": [
        "# Jeans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr3vZTcspBBV",
        "outputId": "9e5a4cfa-e849-4741-d388-39032ae3de97"
      },
      "source": [
        "# Calling the function and scraping the 'Jeans(men)' category images.\n",
        "\n",
        "images(\"https://www.amazon.com/\", folder, labels, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search Category : Jeans men\n",
            "\n",
            "Page 1\n",
            "Downloads of images from Page 1 is completed! \n",
            "\n",
            "\n",
            "Page 2\n",
            "Downloads of images from Page 2 is completed! \n",
            "\n",
            "\n",
            "Page 3\n",
            "Downloads of images from Page 3 is completed! \n",
            "\n",
            "\n",
            "Page 4\n",
            "Downloads of images from Page 4 is completed! \n",
            "\n",
            "\n",
            "Page 5\n",
            "Downloads of images from Page 5 is completed! \n",
            "\n",
            "Total images downlaoded of Jeans men :  309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyRKkq7irXUi"
      },
      "source": [
        "# Trousers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVpkscoApBFR",
        "outputId": "af1fc2b3-52ae-4b78-cf2b-4c421cbbd55a"
      },
      "source": [
        "# Calling the function and scraping the 'Trousers(men)' category images.\n",
        "\n",
        "images(\"https://www.amazon.com/\", folder, labels, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search Category : Trousers men\n",
            "\n",
            "Page 1\n",
            "Downloads of images from Page 1 is completed! \n",
            "\n",
            "\n",
            "Page 2\n",
            "Downloads of images from Page 2 is completed! \n",
            "\n",
            "\n",
            "Page 3\n",
            "Downloads of images from Page 3 is completed! \n",
            "\n",
            "\n",
            "Page 4\n",
            "Downloads of images from Page 4 is completed! \n",
            "\n",
            "\n",
            "Page 5\n",
            "Downloads of images from Page 5 is completed! \n",
            "\n",
            "Total images downlaoded of Trousers men :  311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "VizrFoj4pBHC",
        "outputId": "f00ae718-5588-423a-edc0-f9591d3e8e32"
      },
      "source": [
        "# Converting the 'labels' list into dataframe.\n",
        "\n",
        "df = pd.DataFrame(labels)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>901</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>902</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>903</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>904</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>906 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0\n",
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "..  ..\n",
              "901  2\n",
              "902  2\n",
              "903  2\n",
              "904  2\n",
              "905  2\n",
              "\n",
              "[906 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izQPXQPxpBKz"
      },
      "source": [
        "# Saving the scrapped data labels in csv format.\n",
        "\n",
        "df.to_csv(\"data1.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T1UAk8ese9S"
      },
      "source": [
        "# End of Document"
      ]
    }
  ]
}